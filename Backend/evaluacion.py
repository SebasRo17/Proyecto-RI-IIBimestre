import os
import torch
import numpy as np
from tqdm import tqdm
from transformers import CLIPProcessor, CLIPModel

# ğŸ“ Rutas
DATA_DIR = r"C:\Users\roble\OneDrive\Documentos\GitHub\Proyecto-RI-IIBimestre\Data"
EMBEDDINGS_DIR = os.path.join(DATA_DIR, "embeddings")
ANNOTATIONS_FILE = os.path.join(DATA_DIR, "ExpertAnnotations.txt")
CAPTIONS_FILE = os.path.join(DATA_DIR, "Flickr8k.lemma.token.txt")

# ğŸ” Cargar modelo CLIP
device = "cuda" if torch.cuda.is_available() else "cpu"
model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32").to(device)
processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

# ğŸ“¥ Cargar embeddings de imÃ¡genes y nombres
image_embeddings = np.load(os.path.join(EMBEDDINGS_DIR, "image_embeddings.npy")).astype("float32")
with open(os.path.join(EMBEDDINGS_DIR, "image_names.txt"), "r", encoding="utf-8") as f:
    image_names = [line.strip() for line in f.readlines()]

# ğŸ§  FunciÃ³n para generar embedding de texto
def get_text_embedding(text):
    inputs = processor(text=[text], return_tensors="pt", padding=True).to(device)
    with torch.no_grad():
        emb = model.get_text_features(**inputs)
    return emb.cpu().numpy().flatten()

# ğŸ“Š Inicializar mÃ©tricas
ranks = []
top1 = 0
top5 = 0
total = 0

# ğŸ“„ Cargar captions a memoria
captions_dict = {}
with open(CAPTIONS_FILE, "r", encoding="utf-8") as f:
    for line in f:
        parts = line.strip().split("\t")
        if len(parts) == 2:
            captions_dict[parts[0]] = parts[1]

# ğŸ§ª EvaluaciÃ³n
with open(ANNOTATIONS_FILE, "r", encoding="utf-8") as f:
    for line in tqdm(f, desc="ğŸ§ª Evaluando"):
        parts = line.strip().split()
        if len(parts) < 5:
            continue

        image_file, caption_id, s1, s2, s3 = parts
        if caption_id not in captions_dict:
            continue

        caption_text = captions_dict[caption_id]

        try:
            query_emb = get_text_embedding(caption_text)
            dists = np.linalg.norm(image_embeddings - query_emb, axis=1)
            sorted_indices = np.argsort(dists)

            if image_file in image_names:
                correct_idx = image_names.index(image_file)
                rank = np.where(sorted_indices == correct_idx)[0][0]
                ranks.append(rank)
                total += 1
                if rank == 0:
                    top1 += 1
                if rank < 5:
                    top5 += 1
        except Exception as e:
            print(f"âš ï¸ Error con {caption_id}: {e}")

# ğŸ“ˆ Reporte
if total == 0:
    print("âŒ No se pudo evaluar ninguna muestra.")
else:
    print(f"\nğŸ“Š Resultados de EvaluaciÃ³n sobre {total} pares imagen-caption:")
    print(f"ğŸ… Top-1 Accuracy: {top1 / total:.4f}")
    print(f"ğŸ… Top-5 Accuracy: {top5 / total:.4f}")
    print(f"ğŸ“ˆ Mean Rank: {np.mean(ranks):.2f}")